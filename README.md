# 와인 데이터 품질 분류 🍷

## 프로젝트 개발 기간
2024.06.01 ~ 2024.06.15

[프로젝트 노트북 보기](wine_quality.ipynb)  
[PDF 파일 보기](와인_품질_분류.pdf)

## 프로젝트 설계
Red Wine Quality Dataset을 분석하여 dataset 내에 quality를 예측하는 분류 프로젝트입니다.

## 문제 설명
목표는 데이터 테이블 내의 와인의 다양한 feature들 기반으로 와인의 품질을 예측하는 것입니다(3, 4, 5, 6, 7, 8). 이를 위해 여러 머신러닝 모델을 사용하여 예측 모델을 구축하고 성능을 평가합니다.

![와인 데이터](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled.png)
와인 품질 예측 프로젝트는 "분류"에 해당합니다. 구체적으로, 여기에서 와인 데이터셋은 품질을 3, 4, 5, 6, 7, 8 등급으로 나누었기 때문에 "다중 분류"라고 볼 수 있습니다.

## 데이터 수집 및 전처리

### 전처리 작업
- 결측치 확인 결과 결측치가 한 개도 없음을 확인.
![결측치 확인](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled1.png)
- 이상치 제거: 데이터프레임에서 1사분위수와 3사분위수를 계산하고 이를 통해 IQR을 계산함. 각 열의 값이 1사분위수에서 1.5*IQR만큼 아래에 있거나, 3사분위수에서 1.5*IQR만큼 위에 있는 경우를 이상치로 간주하고 제거함.
![이상치 제거](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled2.png)
- 데이터 정규화: MinMaxScaler, RobustScale, StandardScaler, Normalizer 방법 중 RobustScale, StandardScaler 정규화 방법이 가장 모델의 정확도가 높아 둘 중 결과적으로 높게 나오는 것을 사용하기로 함.

## 탐색적 데이터 분석 (EDA)
![와인 품질 히스토그램](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled3.png)
- 와인의 품질은 3~8로 이루어져 있으며, 5와 6 사이에 주로 분포하고 있음.
- 5와 6 사이에 데이터가 집중되어 있어, 이는 과적합의 가능성이 있음.
- 품질이 3 또는 8인 와인은 상대적으로 매우 적으며 이는 이상치로 볼 수 있음.
![상관 관계 그래프](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled4.png)
- alcohol(0.5), quality(1), sulphates(0.3) 양의 상관관계를 보여줌.
- volatile acidity(-0.4) 음의 상관관계를 보여줌.
- 이 요인들을 이용해 후에 모델의 정확도를 추가적으로 높일 수 있음.

## 베이스라인 모델 (튜닝 전)
- 사용할 모델: 로지스틱 회귀, 랜덤 포레스트, XGBoost
1. quality를 제외한 컬럼을 특징 행렬로 사용하고, quality 컬럼은 레이블 인코딩하여 타켓 변수로 사용.
2. 데이터셋을 train용으로 80%, test용으로 20% 나눔.
3. 각각의 모델 학습 및 예측

### 튜닝 없이 모델 성능 평가 결과
![모델 성능 평가](https://github.com/jungoat/Wine_quality/blob/master/readme_images/Untitled5.png)
- 랜덤 포레스트의 정확도가 가장 높음: 와인 데이터의 특성 상 비선형 관계일 가능성이 높아, 비선형 데이터에 대해 강력한 성능을 발휘하는 랜덤 포레스트가 정확도가 높음.
- 로지스틱 회귀의 정확도가 가장 낮음: 모델이 선형일 때 강력한 성능을 드러내기 때문에 와인데이터에서 로지스틱 회귀를 사용하는 것은 적합하지 않음.
- XGBoost가 정확도가 높지 않은 이유: XGBoost는 복잡한 모델로, 하이퍼파라미터 튜닝이 성능에 가장 큰 영향을 미치므로 기본 설정으로 평가할 경우 랜덤 포레스트보다 성능이 낮을 수 있음.

## 모델 튜닝
1. **smote**를 사용하여 와인 품질 중 샘플 수가 적은 3, 8 등급에 품질에 와인들에 클래스 불균형을 해결함.
2. 정규화 방법으로 **StandardScaler**를 사용함.
3. RandomForestClassifier, SVC 두 모델의 시드를 100으로 설정 후 모델을 학습시킴.

### 정확도 결과
- rfc Accuracy: 85.0856
- svc Accuracy: 77.5061

랜덤 포레스트의 정확도가 높아 이를 하이퍼파라미터 튜닝하기로 결정. 랜덤포레스트 하이퍼파라미터 튜닝은 그리드 서치를 활용함.

### 파라미터 종류
1. **n_estimators**: 랜덤 포레스트 안의 결정 트리 수. 트리 수가 많을수록 성능이 좋아질 수 있지만, 계산 비용이 증가함.
2. **max_features**: 각 분할에서 고려할 최대 피처 수.
3. **max_depth**: 각 트리의 최대 깊이.
4. **min_samples_split**: 내부 노드를 분할하기 위한 최소 샘플 수.
5. **min_samples_leaf**: 리프 노드에 있어야 하는 최소 샘플 수.
6. **bootstrap**: 부트스트랩 샘플링을 사용할지 여부.
7. **criterion**: 분할 품질을 평가하는 기준. "gini" 또는 "entropy", "log_loss".

이 중 모델의 정확도를 높이는데 유의미한 파라미터 3가지 **n_estimators, criterion, max_features**을 사용했습니다. 이유는 이 세 가지 파라미터는 모델의 안정성과 다양성에 도움을 주며 모델이 과적합이 되지 않도록 합니다.

## 하이퍼파라미터 튜닝 결과
그리드 서치를 통해 구한 최적의 하이퍼파라미터는 다음과 같습니다:
- Criterion: entropy
- Max_features: sqrt
- N_estimators: 300

accuracy: 0.8705689809965584

N_estimator의 경우 그리드 서치 중 80, 120, 240, 300 순서대로 서치를 한 결과 N_estimator의 값이 증가할수록 정확도가 높아졌지만, 증가율이 점점 감소했고 300보다 큰 경우에는 오히려 정확도가 낮게 나왔습니다.

## 결과 분석 및 시각화
3가지 모델 중 하이퍼 파라미터를 최적화 한 Random Forest가 AUC가 가장 높으므로, Random Forest 모델을 최종 모델로 결정.

## 결론
### 결과 요약:
- **모델 성능**
  - 랜덤 포레스트, 로지스틱 회귀, XGBoost 모델을 비교 평가한 결과, ROC 커브와 AUC를 통해 각 모델의 성능을 시각화하고 비교했습니다.
  - ROC 커브를 통해 와인의 품질을 예측하는 최고의 모델은 랜덤 포레스트로 선정되었습니다.

### 배운 점:
1. **데이터 전처리 및 정규화의 중요성**: 전처리 및 정규화 과정에서 결측치 처리 및 이상치 제거가 모델의 성능을 평가하는데 큰 영향을 미친다는 점을 경험적으로 느꼈습니다. 데이터의 특성에 맞는 정규화 방법을 선택해야 한다는 중요성을 배웠습니다.
2. **탐색적 데이터 분석(EDA)**: 데이터의 분포와 피처 간의 상관관계를 시각화하여 피처 간의 상관관계를 파악하는 것이 모델의 성능을 높이는데 매우 중요하다는 것을 깨달았습니다.
3. **다양한 머신러닝 모델 사용**: 여러 머신러닝 모델을 사용하여 성능을 평가했습니다. 특히, 랜덤 포레스트가 와인 데이터셋에 대해 가장 높은 성능을 냈고, 왜 그런지에 대한 이유를 분석하면서 각 모델들마다 어떤 데이터에서 강한 퍼포먼스를 보여주는지 알게 되었습니다.
4. **하이퍼 파라미터 튜닝**: 그리드 서치를 통해 하이퍼파라미터 튜닝을 진행했습니다. 튜닝을 하면서 n_estimator을 높일수록 정확도가 높았지만 어느 정도 크기 이후로는 오르지 않았습니다. 이를 통해 최적의 하이퍼 파라미터를 구하기 위해 어떤 파라미터를 튜닝 해야 할지 판단하는 방법을 배웠습니다.
